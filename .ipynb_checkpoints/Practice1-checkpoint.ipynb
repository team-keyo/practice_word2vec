{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考\n",
    "https://github.com/danielfrg/word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 準備\n",
    "\n",
    "[Anaconda](https://www.continuum.io/downloads) からインストールしたPythonにword2vec をインストール。\n",
    "\n",
    "`pip install word2vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データのダウンロード\n",
    "\n",
    "http://mattmahoney.net/dc/text8.zip\n",
    "をダウンロードし、適当なフォルダに解答する。\n",
    "\n",
    "とりあえず、このディレクトリにフォルダを作成する（容量が大きいので.gitignoreしている。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run word2phrase to group up similar words \"Los Angeles\" to \"Los_Angeles\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "word2vec.word2phrase('./text8/text8', './text8/text8-phrases', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a text8-phrases that we can use as a better input for word2vec. Note that you could easily skip this previous step and use the origial data as input for word2vec.\n",
    "\n",
    "Train the model using the word2phrase output."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "word2vec.word2vec('./text8/text8-phrases', './text8/text8.bin', size=100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That generated a text8.bin file containing the word vectors in a binary format.\n",
    "\n",
    "Do the clustering of the vectors based on the trained model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "word2vec.word2clusters('./text8/text8', './text8/text8-clusters.txt', 100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "Import the word2vec binary file created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = word2vec.load('./text8/text8.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the vocabulaty as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['</s>', 'the', 'of', ..., 'denishawn', 'tamiris', 'dolophine'], \n",
       "      dtype='<U78')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or take a look at the whole matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98331, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14333282,  0.15825513, -0.13715845, ...,  0.05456942,\n",
       "         0.10955409,  0.00693387],\n",
       "       [ 0.12324433,  0.08508522, -0.14245066, ..., -0.05163304,\n",
       "        -0.04413069, -0.02636524],\n",
       "       [ 0.09120493,  0.07657887,  0.09830743, ..., -0.07062475,\n",
       "         0.00264537,  0.1461402 ],\n",
       "       ..., \n",
       "       [-0.05293642, -0.05607885,  0.12834577, ...,  0.01149706,\n",
       "        -0.23037991, -0.0393982 ],\n",
       "       [-0.08716934, -0.0674235 ,  0.13691288, ...,  0.11314875,\n",
       "        -0.28018489, -0.05091289],\n",
       "       [ 0.19590881,  0.05077619,  0.0686731 , ...,  0.1524414 ,\n",
       "        -0.09329432,  0.06795349]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retreive the vector of individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['dog'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16765068, -0.06553809,  0.02739922,  0.05225474,  0.15062518,\n",
       "       -0.06210165,  0.05994908,  0.03833631,  0.12365534,  0.14278004])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['dog'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do simple queries to retreive words similar to \"socks\" based on cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14558, 20175, 29181, 34047, 31618, 22883, 23666, 30402, 20336, 37766]),\n",
       " array([ 0.83670478,  0.83519267,  0.82714757,  0.82426758,  0.82154239,\n",
       "         0.81419191,  0.81361981,  0.81271618,  0.80641576,  0.80382507]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.cosine('socks')\n",
    "indexes, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returned a tuple with 2 items:\n",
    "\n",
    "numpy array with the indexes of the similar words in the vocabulary\n",
    "numpy array with cosine similarity to each word\n",
    "Its possible to get the words of those indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['winged', 'hairy', 'pumpkin', 'nosed', 'straps', 'skirt', 'striped',\n",
       "       'gravy', 'crab', 'boa'], \n",
       "      dtype='<U78')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a helper function to create a combined response: a numpy record array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([('winged', 0.8367047800859084), ('hairy', 0.8351926650699733),\n",
       " ('pumpkin', 0.8271475672165035), ('nosed', 0.8242675798607484),\n",
       " ('straps', 0.8215423863858035), ('skirt', 0.8141919128224772),\n",
       " ('striped', 0.8136198096480802), ('gravy', 0.8127161761603303),\n",
       " ('crab', 0.8064157558571379), ('boa', 0.8038250736592599)], \n",
       "          dtype=[('word', '<U78'), ('metric', '<f8')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_response(indexes, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is easy to make that numpy array a pure python response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('winged', 0.8367047800859084),\n",
       " ('hairy', 0.8351926650699733),\n",
       " ('pumpkin', 0.8271475672165035),\n",
       " ('nosed', 0.8242675798607484),\n",
       " ('straps', 0.8215423863858035),\n",
       " ('skirt', 0.8141919128224772),\n",
       " ('striped', 0.8136198096480802),\n",
       " ('gravy', 0.8127161761603303),\n",
       " ('crab', 0.8064157558571379),\n",
       " ('boa', 0.8038250736592599)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrases\n",
    "\n",
    "Since we trained the model with the output of word2phrase we can ask for similarity of \"phrases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('san_francisco', 0.8953364682036224),\n",
       " ('san_diego', 0.8761334153196536),\n",
       " ('las_vegas', 0.8524525856073968),\n",
       " ('miami', 0.8381276706082835),\n",
       " ('seattle', 0.8260420347119275),\n",
       " ('california', 0.8217981543657138),\n",
       " ('chicago', 0.8142463083479377),\n",
       " ('st_louis', 0.8121326055898652),\n",
       " ('chicago_illinois', 0.8101182172944901),\n",
       " ('dallas', 0.8080168522391078)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.cosine('los_angeles')\n",
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogies\n",
    "Its possible to do more complex queries like analogies such as: king - man + woman = queen This method returns the same as cosine the indexes of the words in the vocab and the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1088,  1145,  7540,   344,  3141,  4978,  1827,  1335,  1427, 13088]),\n",
       " array([ 0.28635165,  0.27244199,  0.26373954,  0.26257615,  0.26253012,\n",
       "         0.26074491,  0.26011973,  0.25957689,  0.25923383,  0.25913231]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.analogy(pos=['king', 'woman'], neg=['man'], n=10)\n",
    "indexes, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.2863516507498973),\n",
       " ('prince', 0.2724419886339948),\n",
       " ('empress', 0.263739540598119),\n",
       " ('son', 0.2625761524291093),\n",
       " ('monarch', 0.2625301180985256),\n",
       " ('heir', 0.26074491063702476),\n",
       " ('throne', 0.2601197344276091),\n",
       " ('wife', 0.25957688950021474),\n",
       " ('bishop', 0.25923383068212613),\n",
       " ('king_edward', 0.25913230551757593)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = word2vec.load_clusters('./text8/text8-clusters.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see get the cluster number for individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word2vec.wordclusters.WordClusters"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'</s>', b'the', b'of', ..., b'denishawn', b'tamiris', b'dolophine'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[b'dog']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see get all the words grouped on an specific cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.get_words_on_cluster(90).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'or', b'common', b'important', b'making', b'complex', b'simple',\n",
       "       b'direct', b'difficult', b'active', b'alternative'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.get_words_on_cluster(90)[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can add the clusters to the word2vec model and generate a response that includes the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.clusters = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexes, metrics = \\\n",
    "    model.analogy(pos=['paris', 'germany'], neg=['france'], n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('berlin', 0.32607859249215876, 20),\n",
       " ('vienna', 0.28917846478744846, 82),\n",
       " ('munich', 0.2843345925557563, 5),\n",
       " ('leipzig', 0.2792443656190464, 41),\n",
       " ('moscow', 0.27522173121249416, 59),\n",
       " ('st_petersburg', 0.26281150847112744, 63),\n",
       " ('prague', 0.2596628868838047, 19),\n",
       " ('dresden', 0.25564775446499577, 86),\n",
       " ('z_rich', 0.2543353152525521, 71),\n",
       " ('bonn', 0.2520885868719889, 10)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
